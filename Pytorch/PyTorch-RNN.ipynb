{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent Neural Networks (RNN)\n",
    "Traditional feed-forward neural networks take in a fixed amount of input data all at the same time and produce a fixed amount of output each time. On the other hand, RNNs do not consume all the input data at once. Instead, they take them in one at a time and in a sequence. At each step, the RNN does a series of calculations before producing an output. The output, known as the hidden state, is then combined with the next input in the sequence to produce another output. This process continues until the model is programmed to finish or the input sequence ends.\n",
    "\n",
    "The calculations at each time step consider the context of the previous time steps in the form of the hidden state. Being able to use this contextual information from previous inputs is the key essence to RNNs’ success in sequential problems.\n",
    "\n",
    "While it may seem that a different RNN cell is being used at each time step in the graphics, the underlying principle of Recurrent Neural Networks is that the RNN cell is actually the exact same one and reused throughout.\n",
    "#### Long Short Term Memory Networks (LTSMs)\n",
    "Recurrent Neural Networks can also be divided into units called Long Short Term Memory (LTSM) if there are feedback loops present, or delays of time. In this case, you would have mitigated flow of the input data through the neural network. This allows the neural network to prioritize between what is **important** vs. **non-important** information.\n",
    "One LTSM is composed of a:\n",
    "- **Memory cell**: where the input data resides. It’s a container where all the action happens. The gates on its perimeter are able to control what information flows through it and how the input is handled.\n",
    "- **Input Gate**: This is where the input enters the cell (obviously). There is a tanh activation function because the gate decides whether to let the input data in or erase the present state, and how the input will affect the output. You can see this in the diagram below as it is represented by the middle two activation functions.\n",
    "- **Output Gate**: This is shown in the diagram by the activation function on the right side. It regulates and filters the output of the function.\n",
    "- **Forget Gate**: You don’t actually always need the previous input information for the following one. This allows you to rid of information that was previously stored. For example: say you input “Angelica is my friend. Logan is Sam’s cousin.”, then it will ‘forget’ all the data before “friend” by the time it reaches “Logan”. It is seen in the activation function the furthest on the left side.\n",
    "\n",
    "In general LTSMs are used to classify, identify, or predict output data accordingly based on a series of discrete-time input data. They use gradient descent and back propagation algorithms to minimize error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN_Classification_Net(\n",
      "  (basic_rnn): RNN(28, 150)\n",
      "  (FC): Linear(in_features=150, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class RNN_Classification_Net(nn.Module):\n",
    "    def __init__(self, device, batch_size, n_steps, n_inputs, n_neurons, n_outputs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.device = device\n",
    "        self.n_neurons = n_neurons\n",
    "        self.batch_size = batch_size\n",
    "        self.n_steps = n_steps\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_outputs = n_outputs\n",
    "        \n",
    "        self.basic_rnn = nn.RNN(n_inputs, n_neurons)\n",
    "        \n",
    "        self.FC = nn.Linear(self.n_neurons, self.n_outputs)\n",
    "        \n",
    "    def init_hidden(self,):\n",
    "        # (num_layers, batch_size, n_neurons)\n",
    "        return (torch.zeros(1, self.batch_size, self.n_neurons).to(self.device))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # transforms X to dimensions: n_steps X batch_size X n_inputs\n",
    "        X = X.view(-1, 28,28) \n",
    "        X = X.permute(1, 0, 2) \n",
    "        \n",
    "        self.batch_size = X.size(1)\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "        lstm_out, self.hidden = self.basic_rnn(X, self.hidden)      \n",
    "        out = self.FC(self.hidden)\n",
    "        \n",
    "        return out.view(-1, self.n_outputs) # batch_size X n_output\n",
    "\n",
    "\n",
    "DEVICE = \"cuda\" if torch.has_cuda else \"cpu\"\n",
    "BATCH_SIZE = 64\n",
    "N_STEPS = 28\n",
    "N_INPUTS = 28\n",
    "N_NEURONS = 150\n",
    "N_OUTPUTS = 10\n",
    "\n",
    "RNN_Model = RNN_Classification_Net(DEVICE,BATCH_SIZE, N_STEPS, N_INPUTS, N_NEURONS, N_OUTPUTS).to(DEVICE)\n",
    "print(RNN_Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.300172  [    0/60000]\n",
      "loss: 0.592000  [32000/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.4%, Avg loss: 0.654331 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.431172  [    0/60000]\n",
      "loss: 0.638750  [32000/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.580906 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.608246  [    0/60000]\n",
      "loss: 0.437673  [32000/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.518366 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.360196  [    0/60000]\n",
      "loss: 0.355520  [32000/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.537505 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.526343  [    0/60000]\n",
      "loss: 0.468028  [32000/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.550994 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.343049  [    0/60000]\n",
      "loss: 0.423382  [32000/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.454628 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.445706  [    0/60000]\n",
      "loss: 0.483376  [32000/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.430919 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.478370  [    0/60000]\n",
      "loss: 0.519384  [32000/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.443703 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.331442  [    0/60000]\n",
      "loss: 0.296816  [32000/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.420996 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.316326  [    0/60000]\n",
      "loss: 0.387225  [32000/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.443723 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision.transforms import ToTensor,RandomPerspective,RandomRotation\n",
    "\n",
    "#Loading the data\n",
    "training_data = FashionMNIST(\n",
    "    root=\"data\", #Path to the data\n",
    "    train=True, #Are the data for training\n",
    "    download=True, #Download the data if they don't exist\n",
    "    transform=ToTensor() #Transform the feature and label into tensors\n",
    ")\n",
    "\n",
    "test_data = FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "\n",
    "#Loading the data in a dataloader\n",
    "train_dataloader = DataLoader(training_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "#Implementing both training and testing sets\n",
    "def train_loop(dataloader, model, loss_fn, optimizer, scheduler):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # reset hidden states\n",
    "        model.hidden = model.init_hidden()\n",
    "        \n",
    "        # Setting up the inputs\n",
    "        X = X.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()#reset the gradients of model parameters. Gradients by default add up; to prevent double-counting, we explicitly zero them at each iteration.\n",
    "        loss.backward()#Backpropagate the prediction loss\n",
    "        optimizer.step()#adjust the parameters by the gradients collected in the backward pass.\n",
    "\n",
    "        if batch % 500 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    scheduler.step()\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad(): #Emptying the gradients\n",
    "        for X, y in dataloader:\n",
    "            # Setting up the inputs\n",
    "            X = X.to(DEVICE)\n",
    "            y = y.to(DEVICE)\n",
    "\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "#Defining the Training Parameters\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(RNN_Model.parameters(),lr = 0.001,weight_decay = 0.001)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "epochs = 10\n",
    "\n",
    "#Starting the training and testing\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, RNN_Model, loss_fn, optimizer, scheduler)\n",
    "    test_loop(test_dataloader, RNN_Model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input and hidden tensors are not at the same device, found input tensor at cpu and hidden tensor at cuda:0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\SelfTrainning\\Deep-learning\\Pytorch\\PyTorch-RNN.ipynb Zelle 4\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SelfTrainning/Deep-learning/Pytorch/PyTorch-RNN.ipynb#W6sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# iterate over test data\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SelfTrainning/Deep-learning/Pytorch/PyTorch-RNN.ipynb#W6sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mfor\u001b[39;00m img, label \u001b[39min\u001b[39;00m tqdm(test_data):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/SelfTrainning/Deep-learning/Pytorch/PyTorch-RNN.ipynb#W6sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m         output \u001b[39m=\u001b[39mRNN_Model(img[\u001b[39mNone\u001b[39;49;00m, \u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m])\u001b[39m.\u001b[39margmax(\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SelfTrainning/Deep-learning/Pytorch/PyTorch-RNN.ipynb#W6sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m         y_pred\u001b[39m.\u001b[39mappend(output\u001b[39m.\u001b[39mitem()) \u001b[39m# Save Prediction\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SelfTrainning/Deep-learning/Pytorch/PyTorch-RNN.ipynb#W6sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m         y_true\u001b[39m.\u001b[39mappend(label) \u001b[39m# Save Truth\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\VIRGA\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32md:\\SelfTrainning\\Deep-learning\\Pytorch\\PyTorch-RNN.ipynb Zelle 4\u001b[0m in \u001b[0;36mRNN_Classification_Net.forward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SelfTrainning/Deep-learning/Pytorch/PyTorch-RNN.ipynb#W6sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SelfTrainning/Deep-learning/Pytorch/PyTorch-RNN.ipynb#W6sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minit_hidden()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/SelfTrainning/Deep-learning/Pytorch/PyTorch-RNN.ipynb#W6sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m lstm_out, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbasic_rnn(X, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhidden)      \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SelfTrainning/Deep-learning/Pytorch/PyTorch-RNN.ipynb#W6sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mFC(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SelfTrainning/Deep-learning/Pytorch/PyTorch-RNN.ipynb#W6sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mreturn\u001b[39;00m out\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs)\n",
      "File \u001b[1;32mc:\\Users\\VIRGA\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\VIRGA\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:268\u001b[0m, in \u001b[0;36mRNNBase.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    266\u001b[0m _impl \u001b[39m=\u001b[39m _rnn_impls[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode]\n\u001b[0;32m    267\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 268\u001b[0m     result \u001b[39m=\u001b[39m _impl(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[0;32m    269\u001b[0m                    \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[0;32m    270\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    271\u001b[0m     result \u001b[39m=\u001b[39m _impl(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[0;32m    272\u001b[0m                    \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Input and hidden tensors are not at the same device, found input tensor at cpu and hidden tensor at cuda:0"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "wrong_preds = []\n",
    "\n",
    "RNN_Model.hidden.to(\"cpu\")\n",
    "RNN_Model.to(\"cpu\")\n",
    "\n",
    "# iterate over test data\n",
    "for img, label in tqdm(test_data):\n",
    "        output =RNN_Model(img[None, ...]).argmax(1)\n",
    "        y_pred.append(output.item()) # Save Prediction\n",
    "        y_true.append(label) # Save Truth\n",
    "        if label != output:\n",
    "            wrong_preds.append((img,label))\n",
    "\n",
    "# images that the model predicted wrong\n",
    "print(f\"Out of {len(test_data)} images the model has predicted {len(wrong_preds)} wrong images\")\n",
    "\n",
    "# Build confusion matrix\n",
    "classes = ['T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot']\n",
    "\n",
    "# Build confusion matrix\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix) *10,\n",
    "                    index = [i for i in classes],\n",
    "                    columns = [i for i in classes]) #instead of numbers to get a precentage\n",
    "plt.figure(figsize = (12,7))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "\n",
    "# Visualizing random images that the model predicted wrong\n",
    "figure = plt.figure(figsize=(12, 12))\n",
    "cols, rows = 3, 4\n",
    "\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(wrong_preds), size=(1,)).item() \n",
    "    img, label = wrong_preds[sample_idx]\n",
    "\n",
    "    pred = RNN_Model(img[None, ...]).argmax(1)\n",
    "\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(f\"Pred: {classes[pred.item()]}, Label: {classes[label]}\", fontdict={\"fontsize\": 14, \"color\": (\"green\" if pred.item() == label else \"red\")})\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.cpu().squeeze()) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2e91d28eebfc6725d30a16a257ad1f1e588a28b9f99818e7d9d7a22c6e941ff4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
